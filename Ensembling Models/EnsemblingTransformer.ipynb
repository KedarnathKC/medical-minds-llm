{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-IySwmYahyZ",
        "outputId": "b9ff6347-05b6-495f-e701-189c9b43921e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-ubgnids5/unsloth_e6854c2c46ce4ea3a7b31138abefddd0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-ubgnids5/unsloth_e6854c2c46ce4ea3a7b31138abefddd0\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 8dc0561ec0776fcc49d8a406c8a0acf295bd561a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tyro (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading tyro-0.8.4-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.38.2 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.40.2)\n",
            "Collecting datasets>=2.16.0 (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.99)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.43.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.25.2)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.31.0)\n",
            "Collecting xxhash (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.38.2->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.3)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.11.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.7.1)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.16.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
            "Building wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2024.5-py3-none-any.whl size=105043 sha256=127ae44c3f982c876c6a5b36230cb8196602e213749ceed3fe0b06afab438f53\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-9yw0nnkt/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n",
            "Successfully built unsloth\n",
            "Installing collected packages: xxhash, unsloth, shtab, dill, multiprocess, huggingface-hub, tyro, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 shtab-1.7.1 tyro-0.8.4 unsloth-2024.5 xxhash-3.4.1\n",
            "Collecting xformers<0.0.26\n",
            "  Downloading xformers-0.0.25.post1-cp310-cp310-manylinux2014_x86_64.whl (222.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.5/222.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl\n",
            "  Downloading trl-0.8.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft\n",
            "  Downloading peft-0.11.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes, xformers, trl, peft, accelerate\n",
            "Successfully installed accelerate-0.30.1 bitsandbytes-0.43.1 peft-0.11.0 trl-0.8.6 xformers-0.0.25.post1\n"
          ]
        }
      ],
      "source": [
        "# Requried Installations\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.26\" trl peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOax9mQIapxb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Transformer Based Ensembling Model Defination"
      ],
      "metadata": {
        "id": "0p9bcRtwLlJA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWHLHTh6atx7"
      },
      "outputs": [],
      "source": [
        "class SingleHeadAttention(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SingleHeadAttention, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        # Learnable parameters\n",
        "        self.query = nn.Linear(input_dim, input_dim)\n",
        "        self.key = nn.Linear(input_dim, input_dim)\n",
        "        self.value = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "        # self.out = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Calculate query, key, and value\n",
        "        Q = self.query(x)\n",
        "        K = self.key(x)\n",
        "        V = self.value(x)\n",
        "\n",
        "        # Calculate attention scores\n",
        "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.input_dim, dtype=torch.float32))\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # Calculate attention output\n",
        "        attention_output = torch.matmul(attention_weights, V)\n",
        "\n",
        "        # output = self.out(attention_output)\n",
        "\n",
        "        return attention_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8fTCwF8cO1w"
      },
      "outputs": [],
      "source": [
        "class FusionTransformer(nn.Module):\n",
        "    def __init__ (self,model1,model2,modelSize=32000,device='cuda'):\n",
        "      super().__init__()\n",
        "\n",
        "      self.model1 = model1.to(device)\n",
        "      self.model2 = model2.to(device)\n",
        "      self.linear1 = nn.Linear(modelSize,4).to(device)\n",
        "      self.linear2 = nn.Linear(modelSize,4).to(device)\n",
        "      self.transformer = SingleHeadAttention(input_dim=4*2).to(device)\n",
        "      # self.transformer = nn.Transformer(d_model=8,nhead=1,num_encoder_layers=1,num_decoder_layers=1).to(device)\n",
        "      # self.relu = nn.ReLU()\n",
        "      self.linear = nn.Linear(8, 4).to(device)\n",
        "\n",
        "    def forward(self,inputIndices, attn_mask):\n",
        "      y1 = self.model1(inputIndices, attn_mask = attn_mask).logits\n",
        "      y2 = self.model2(inputIndices, attn_mask = attn_mask).logits\n",
        "\n",
        "      n,h,w = y1.shape\n",
        "\n",
        "      y1 = y1[:,h-1,:]\n",
        "      y2 = y2[:,h-1,:]\n",
        "      y1 = self.linear1(y1)\n",
        "      y2 = self.linear2(y2)\n",
        "      y = torch.cat((y1,y2),dim=1)\n",
        "      y = self.transformer(y)\n",
        "      y = self.linear(y)\n",
        "\n",
        "      return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Data Import </h2>"
      ],
      "metadata": {
        "id": "xTjPPzxjLsXo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3irKZrJyc2uf"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, load_from_disk, concatenate_datasets, Dataset,DatasetDict\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    MistralForSequenceClassification,\n",
        "    PretrainedConfig,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aaUs5MBc5k7",
        "outputId": "a78e0f90-cad8-423b-c88b-b2e2b4f3ee99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ngC6BWSc60j"
      },
      "outputs": [],
      "source": [
        "dataset_location = \"/content/drive/MyDrive/685 Final Project/Datasets/medmcqa-prompts\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMO-TTMlc-_H"
      },
      "outputs": [],
      "source": [
        "# train_dataset = load_from_disk(f\"{dataset_location}/train_prompts_micro.hf\")\n",
        "# # test_dataset = load_from_disk(f\"{dataset_location}/test_prompts_micro.hf\")\n",
        "# eval_dataset = load_from_disk(f\"{dataset_location}/eval_prompts_micro.hf\")\n",
        "\n",
        "train_dataset = load_from_disk(f\"{dataset_location}/train_prompts_mini.hf\")\n",
        "# test_dataset = load_from_disk(f\"{dataset_location}/test_prompts_mini.hf\")\n",
        "eval_dataset = load_from_disk(f\"{dataset_location}/eval_prompts_mini.hf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N42J4NGpdCHi",
        "outputId": "3feb8ed0-8611-43a3-cb1c-f1d2ef8dbed0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name', 'prompt', 'label_one_hot'],\n",
              "    num_rows: 20000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dv605tddDOd",
        "outputId": "10210061-dc8d-4cbd-feee-5be0b011f3fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'question', 'opa', 'opb', 'opc', 'opd', 'cop', 'choice_type', 'exp', 'subject_name', 'topic_name', 'prompt', 'label_one_hot'],\n",
              "    num_rows: 2000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "eval_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Base Models </h2>"
      ],
      "metadata": {
        "id": "zJZB1Ob-L1h9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IGJHtA0dFtG",
        "outputId": "c76d8b8d-043a-4a80-e5af-a34985eb5d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.5\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. Xformers = 0.0.25.post1. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.5 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.5\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. Xformers = 0.0.25.post1. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained models\n",
        "from unsloth import FastLanguageModel\n",
        "\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model_location = \"/content/drive/MyDrive/685 Final Project/Models\"\n",
        "\n",
        "model1, tokenizer = FastLanguageModel.from_pretrained(model_location + \"/unsloth_domain1\",\n",
        "                                                     max_seq_length=max_seq_length,\n",
        "                                                     dtype=dtype,\n",
        "                                                     load_in_4bit=load_in_4bit)\n",
        "\n",
        "model2, tokenizer = FastLanguageModel.from_pretrained(model_location + \"/ai2_arc_instruction_tuned_mistral_7b_1\",\n",
        "                                                     max_seq_length=max_seq_length,\n",
        "                                                     dtype=dtype,\n",
        "                                                     load_in_4bit=load_in_4bit)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Data Preprocessing</h2>"
      ],
      "metadata": {
        "id": "GxQntV6iL24Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N--Wils-dHvt"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class MCQDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)  # Changed to float for one-hot encoding\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Function to encode the data\n",
        "def encode_data(tokenizer, prompts):\n",
        "    # encodings = tokenizer(prompts, truncation=True, padding=True, max_length=2048)\n",
        "    encodings = tokenizer(prompts, truncation=True, padding=True)\n",
        "    return encodings\n",
        "\n",
        "# Prepare the data for tokenization\n",
        "prompts = [item['prompt'] for item in train_dataset]\n",
        "labels = [item['label_one_hot'] for item in train_dataset]  # one-hot encoded labels\n",
        "\n",
        "# Tokenize data\n",
        "encodings = encode_data(tokenizer, prompts)\n",
        "\n",
        "# Create dataset\n",
        "train_set = MCQDataset(encodings, labels)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "\n",
        "\n",
        "prompts = [item['prompt'] for item in eval_dataset]\n",
        "labels = [item['label_one_hot'] for item in eval_dataset]  # one-hot encoded labels\n",
        "\n",
        "# Tokenize data\n",
        "encodings = encode_data(tokenizer, prompts)\n",
        "\n",
        "# Create dataset\n",
        "eval_set = MCQDataset(encodings, labels)\n",
        "\n",
        "# DataLoader\n",
        "val_loader = DataLoader(eval_set, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Model Training and Evaluation </h2>"
      ],
      "metadata": {
        "id": "1gmch_KKL7F5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLEoxIr3dI1G"
      },
      "outputs": [],
      "source": [
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm import tqdm\n",
        "from torch.nn.functional import softmax\n",
        "def train_and_validate(model, train_loader, val_loader, log_file_path,epochs=3):\n",
        "    best_val_acc=0\n",
        "    saved_model_location = \"/content/drive/MyDrive/685 Final Project/Models\"\n",
        "\n",
        "    scaler = GradScaler()\n",
        "    device = torch.device(\"cuda\")\n",
        "    model = model.to(device)  # Ensures model and all submodules are float32\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # for epoch in tqdm(range(epochs)):\n",
        "    with open(log_file_path, 'a') as log_file:\n",
        "      log_file.write(\"Starting training process...\\n\")\n",
        "      log_file.flush()\n",
        "      print(\"Log File created!\")\n",
        "\n",
        "      for epoch in range(epochs):\n",
        "          total_train_loss = 0\n",
        "          total_train_correct = 0\n",
        "          train_samples = 0\n",
        "          # correct=list()\n",
        "          model.train()\n",
        "          train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} [TRAIN]\", unit=\"batch\")\n",
        "          for i, batch in enumerate(train_pbar):\n",
        "              input_ids, labels, attn_mask = batch['input_ids'].to(device), batch['labels'].to(device), batch['attention_mask'].to(device)\n",
        "              train_samples += labels.size(0)\n",
        "              optimizer.zero_grad()\n",
        "              with torch.cuda.amp.autocast():\n",
        "                  output = model(input_ids,attn_mask).float()\n",
        "                  loss = criterion(output, labels.float())\n",
        "                  predictions = torch.argmax(softmax(output,dim=1), dim=1)\n",
        "                  labels_indices = torch.argmax(labels, dim=1)\n",
        "\n",
        "                  train_correct = (predictions == labels_indices).sum().item()\n",
        "                  total_train_correct += train_correct\n",
        "                  # print(\"\\nTotal Correct : \", train_correct)\n",
        "              log_file.write(f\"Batch {i}, Epoch {epoch+1}, Training Loss: {loss.item():.4f}, Training Accuracy: {100 * total_train_correct / train_samples:.2f}%\\n\")\n",
        "              log_file.flush()\n",
        "\n",
        "              scaler.scale(loss).backward()\n",
        "              scaler.step(optimizer)\n",
        "              scaler.update()\n",
        "              total_train_loss += loss.item()\n",
        "\n",
        "              train_pbar.set_postfix(loss=loss.item(), temp_acc=100 * total_train_correct / train_samples)\n",
        "\n",
        "\n",
        "              # if i % 1000 == 0:\n",
        "              #     print(i, loss.item())\n",
        "              #     print(f\"Temp accuracy: \", total_train_correct / train_samples * 100)\n",
        "\n",
        "              # Releasing the memory\n",
        "              del input_ids, labels, output, loss, predictions, labels_indices\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          avg_train_loss = total_train_loss / len(train_loader)\n",
        "          train_accuracy = total_train_correct / train_samples * 100\n",
        "          print(f\"Training Accuracy: \", train_accuracy)\n",
        "          print(f\"Epoch {epoch+1}, Loss: {avg_train_loss}\")\n",
        "\n",
        "          model.eval()\n",
        "          total_val_loss, val_samples, total_val_correct = 0, 0, 0\n",
        "          eval_pbar = tqdm(val_loader, desc=f\"Epoch {epoch+1} [EVAL]\", unit=\"batch\")\n",
        "          with torch.no_grad():\n",
        "              for i, batch in enumerate(eval_pbar):\n",
        "                  input_ids, labels, attn_mask = batch['input_ids'].to(device), batch['labels'].to(device), batch['attention_mask'].to(device)\n",
        "                  with torch.cuda.amp.autocast():\n",
        "                      outputs = model(input_ids,attn_mask).float()\n",
        "                      val_loss = criterion(outputs, labels.float())\n",
        "                      predictions = torch.argmax(softmax(outputs,dim=1), dim=1)\n",
        "                      labels_indices = torch.argmax(labels, dim=1)\n",
        "                      total_val_correct += (predictions == labels_indices).sum().item()\n",
        "\n",
        "                  total_val_loss += val_loss.item()\n",
        "                  val_samples += labels.size(0)\n",
        "                  eval_pbar.set_postfix(loss=val_loss.item(), temp_acc=100 * total_val_correct / val_samples)\n",
        "\n",
        "          avg_val_loss = total_val_loss / len(val_loader)\n",
        "          val_accuracy = total_val_correct / val_samples * 100\n",
        "\n",
        "          if val_accuracy > best_val_acc:\n",
        "            best_val_acc=val_accuracy\n",
        "            model_save_path = f\"{saved_model_location}/TransformerFusionMiniBest.pth\"\n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "            print(\"Best model Saved at\", model_save_path)\n",
        "\n",
        "          print(f\"Validation Accuracy: \", val_accuracy)\n",
        "          print(f\"Epoch {epoch+1} - Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxJGDNOydK2G"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfEvGP6fLKlv",
        "outputId": "4db6fc2f-947b-4be9-a84b-71ba73040990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e1bec17e990>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_90TgLHDdMJd"
      },
      "outputs": [],
      "source": [
        "ft = FusionTransformer(model1,model2,32000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_file_path = '/content/TransformerFusionMiniLogger.txt'"
      ],
      "metadata": {
        "id": "w0I4rKCWKlIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgd9N73cdovp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e76196-27dc-4648-db25-c1f9daedaca8"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log File created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [TRAIN]: 100%|██████████| 625/625 [1:31:36<00:00,  8.79s/batch, loss=1.4, temp_acc=26.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  26.495\n",
            "Epoch 1, Loss: 1.7152837938308716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [EVAL]: 100%|██████████| 63/63 [01:54<00:00,  1.82s/batch, loss=1.35, temp_acc=31.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model Saved at /content/drive/MyDrive/685 Final Project/Models/TransformerFusionMiniBest.pth\n",
            "Validation Accuracy:  31.85\n",
            "Epoch 1 - Validation Loss: 1.3832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [TRAIN]: 100%|██████████| 625/625 [1:31:36<00:00,  8.79s/batch, loss=1.45, temp_acc=27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  26.979999999999997\n",
            "Epoch 2, Loss: 1.43706215133667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [EVAL]: 100%|██████████| 63/63 [01:54<00:00,  1.82s/batch, loss=1.3, temp_acc=26.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  26.25\n",
            "Epoch 2 - Validation Loss: 1.4317\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [TRAIN]: 100%|██████████| 625/625 [1:31:36<00:00,  8.79s/batch, loss=1.38, temp_acc=26.4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  26.405\n",
            "Epoch 3, Loss: 1.4524910228729249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [EVAL]: 100%|██████████| 63/63 [01:54<00:00,  1.82s/batch, loss=1.42, temp_acc=26.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:  26.25\n",
            "Epoch 3 - Validation Loss: 1.4846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_and_validate(ft,train_loader,val_loader,log_file_path,epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QsXqtmT2E8hF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}